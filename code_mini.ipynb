{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "pre-pro"
      ],
      "metadata": {
        "id": "4V13O0qOo8Iv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKDlMqdqo5HE"
      },
      "outputs": [],
      "source": [
        "!pip install wfdb\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wfdb\n",
        "\n",
        "# Path to dataset (adjust as needed)\n",
        "dataset_path = '/content/ECG_dataset/ECG_dataset/'\n",
        "\n",
        "# Clean up record names (remove any suffixes like - or _)\n",
        "records = [f.split('.')[0] for f in os.listdir(dataset_path) if f.endswith('.atr')]\n",
        "records = list(set(records))\n",
        "records.sort()\n",
        "\n",
        "# Identify unique labels in the dataset\n",
        "unique_labels = set()\n",
        "for record_name in records:\n",
        "    try:\n",
        "        annotations = wfdb.rdann(os.path.join(dataset_path, record_name), 'atr')\n",
        "        unique_labels.update(annotations.symbol)\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred while reading {record_name}: {e}\")\n",
        "\n",
        "print(f\"Unique labels: {unique_labels}\")\n",
        "\n",
        "# Window size setup\n",
        "window_size = 187\n",
        "half_window = window_size // 2\n",
        "\n",
        "# Mapping of heartbeat types to labels\n",
        "mapping = {\n",
        "    'N': 0, 'L': 0, 'R': 0, 'B': 0,   # Normal beats\n",
        "    'A': 1, 'a': 1, 'J': 1, 'S': 1,   # Supraventricular beats\n",
        "    'V': 2, 'E': 2,                   # Ventricular beats\n",
        "    'F': 3,                           # Fusion beats\n",
        "    '/': 4, 'f': 4, 'Q': 4, 'j': 4    # Unknown beats\n",
        "}\n",
        "\n",
        "# Initialize lists to store extracted data\n",
        "heartbeats = []\n",
        "labels = []\n",
        "skip = 0\n",
        "invalid = 0\n",
        "\n",
        "# Read ECG signals and annotations\n",
        "for record_num in records:\n",
        "    set_path = os.path.join(dataset_path, record_num)\n",
        "\n",
        "    try:\n",
        "        # Load ECG record and annotations\n",
        "        record = wfdb.rdrecord(set_path)\n",
        "        ann = wfdb.rdann(set_path, \"atr\")\n",
        "\n",
        "        ecg_signal = record.p_signal[:, 0]  # Take lead 1 (or modify for other leads)\n",
        "        r_peaks = ann.sample\n",
        "        label = ann.symbol\n",
        "\n",
        "        for i, n in enumerate(r_peaks):\n",
        "            start = n - half_window\n",
        "            end = start + window_size\n",
        "\n",
        "            # Skip if the signal is too close to the start or end\n",
        "            if start < 10 or end > len(ecg_signal) - 10:\n",
        "                skip += 1\n",
        "                continue\n",
        "\n",
        "            heart_beat = ecg_signal[start:end]\n",
        "            l = mapping.get(label[i], -1)\n",
        "\n",
        "            if l != -1:\n",
        "                heartbeats.append(heart_beat)\n",
        "                labels.append(l)\n",
        "            else:\n",
        "                invalid += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred at {record_num}: {e}\")\n",
        "\n",
        "# Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame(heartbeats)\n",
        "df['label'] = labels\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = '/content/mitbih_ecg_processed.csv'\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"The data has been stored successfully to {csv_path}\")\n",
        "print(f\"Total heartbeats: {len(heartbeats)}, Skipped: {skip}, Invalid: {invalid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gan"
      ],
      "metadata": {
        "id": "sh0xB9aApTLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load and shuffle the dataset\n",
        "df = pd.read_csv(\"mitbih_ecg_processed.csv\")\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Drop rows with missing labels\n",
        "df = df.dropna(subset=['label'])\n",
        "\n",
        "# Split features and labels\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert training data to DataFrame for GAN input\n",
        "train_df = pd.DataFrame(X_train)\n",
        "train_df['label'] = y_train.reset_index(drop=True)\n",
        "\n",
        "# Filter minority classes\n",
        "minority_classes = [1, 2, 3, 4]\n",
        "minority_df = train_df[train_df['label'].isin(minority_classes)]\n",
        "\n",
        "# Prepare GAN training data\n",
        "X_minority = minority_df.drop('label', axis=1).values\n",
        "y_minority = minority_df['label'].values\n",
        "\n",
        "# Torch Dataset and Dataloader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "data_loader = DataLoader(ECGDataset(X_minority, y_minority), batch_size=64, shuffle=True)\n",
        "\n",
        "# GAN Model Definition\n",
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, output_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "noise_dim = 100\n",
        "input_dim = X_minority.shape[1]\n",
        "\n",
        "gen = Generator(noise_dim, input_dim)\n",
        "disc = Discriminator(input_dim)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(gen.parameters(), lr=0.0002)\n",
        "d_optimizer = torch.optim.Adam(disc.parameters(), lr=0.0002)\n",
        "\n",
        "gen.train()\n",
        "disc.train()\n",
        "\n",
        "# Train GAN\n",
        "for epoch in range(1000):\n",
        "    for real_data, _ in data_loader:\n",
        "        batch_size = real_data.size(0)\n",
        "\n",
        "        # Real and fake labels\n",
        "        real_labels = torch.ones(batch_size, 1)\n",
        "        fake_labels = torch.zeros(batch_size, 1)\n",
        "\n",
        "        # Train discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        outputs = disc(real_data)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "\n",
        "        z = torch.randn(batch_size, noise_dim)\n",
        "        fake_data = gen(z)\n",
        "        outputs = disc(fake_data.detach())\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Train generator\n",
        "        g_optimizer.zero_grad()\n",
        "        z = torch.randn(batch_size, noise_dim)\n",
        "        fake_data = gen(z)\n",
        "        outputs = disc(fake_data)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 200 == 0:\n",
        "        print(f\"Epoch {epoch+1}/1000, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "# Generate synthetic samples per class (e.g., class 1, 2, 3, 4)\n",
        "synthetic_samples = []\n",
        "labels_to_generate = [1, 2, 3, 4]\n",
        "\n",
        "samples_per_class = {1:72286 , 2: 72286, 3: 72286, 4: 72286}\n",
        "\n",
        "for label in labels_to_generate:\n",
        "    n_samples = samples_per_class[label]\n",
        "    z = torch.randn(n_samples, noise_dim)\n",
        "    synth = gen(z).detach().numpy()\n",
        "    synth_df = pd.DataFrame(synth)\n",
        "    synth_df['label'] = label\n",
        "    synthetic_samples.append(synth_df)\n",
        "\n",
        "# Combine all synthetic samples\n",
        "synthetic_df = pd.concat(synthetic_samples, axis=0).reset_index(drop=True)\n",
        "\n",
        "# Combine with real majority class (class 0)\n",
        "real_majority_df = train_df[train_df['label'] == 0]\n",
        "balanced_df = pd.concat([real_majority_df, synthetic_df], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Final checks\n",
        "print(f\"Balanced training data shape: {balanced_df.shape}\")\n",
        "assert balanced_df.shape[1] == 188, \"Expected 187 features and 1 label column.\"\n",
        "assert balanced_df.isnull().sum().sum() == 0, \"Missing values found in balanced data.\"\n",
        "\n",
        "# Save balanced training data before PCA\n",
        "balanced_df.to_csv(\"Balanced_Training_Data_Pre_PCA.csv\", index=False)\n",
        "print(\"Balanced training data saved as 'Balanced_Training_Data_Pre_PCA.csv'\")\n",
        "\n",
        "# PCA on training and test data\n",
        "X_balanced = balanced_df.iloc[:, :-1]\n",
        "y_balanced = balanced_df['label']\n",
        "\n",
        "X_test_df = pd.DataFrame(X_test)\n",
        "X_test_df['label'] = y_test.reset_index(drop=True)\n",
        "\n",
        "pca = PCA(n_components=30)\n",
        "X_bal_pca = pca.fit_transform(X_balanced)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Save PCA-reduced training and test data\n",
        "pd.DataFrame(X_bal_pca).assign(label=y_balanced.reset_index(drop=True)).to_csv(\"Training_PCA.csv\", index=False)\n",
        "pd.DataFrame(X_test_pca).assign(label=y_test.reset_index(drop=True)).to_csv(\"Testing_PCA.csv\", index=False)\n",
        "\n",
        "print(\"PCA reduced training and test data saved as 'Training_PCA.csv' and 'Testing_PCA.csv'\")\n",
        "# Plot label distribution\n",
        "def plot_label_distribution(y, title):\n",
        "    count = pd.Series(y).value_counts().reindex([0, 1, 2, 3, 4], fill_value=0)\n",
        "    plt.bar(count.index, count.values, color='lightblue', edgecolor='black')\n",
        "    for i, v in enumerate(count.values):\n",
        "        plt.text(i, v + 5, str(v), ha='center')\n",
        "    plt.xlabel(\"Class Labels\")\n",
        "    plt.ylabel(\"Samples\")\n",
        "    plt.title(title)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_label_distribution(y_balanced, \"Training Labels Distribution\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_label_distribution(y_test, \"Test Labels Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vXYkecHhpU49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "smote"
      ],
      "metadata": {
        "id": "SFeC0MGxqAsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SMOTE data preparation\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"Training_normalized.csv\")\n",
        "test_data = pd.read_csv(\"Testing_normalized.csv\")\n",
        "\n",
        "# Split features and labels\n",
        "X_train = train_data.iloc[:, :-1]  # All columns except the last one\n",
        "y_train = train_data.iloc[:, -1]   # Last column as target\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "print(f\"Train:{X_train.shape}\")\n",
        "print(f\"Train:{X_test.shape}\")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Apply SMOTE to training data only (important!)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"SMOTE oversampling done!\")\n",
        "print(f\"Oversampled training data shape: {X_train_oversampled.shape}....{y_train_oversampled.shape}\")\n",
        "\n",
        "# Step 2: Now apply PCA to the oversampled data\n",
        "pca = PCA(n_components=30)\n",
        "train_pca = pca.fit_transform(X_train_oversampled)\n",
        "test_pca = pca.transform(X_test)\n",
        "\n",
        "print(\"Data dimensionality reduced with PCA!\")\n",
        "print(f\"Training data: {train_pca.shape}....{y_train_oversampled.shape}\")\n",
        "print(f\"Testing data: {test_pca.shape}....{y_test.shape}\")\n",
        "\n",
        "training=pd.DataFrame(train_pca)\n",
        "training['label']=pd.Series(y_train_oversampled).reset_index(drop=True)\n",
        "training.to_csv(\"Training_PCA_oversampled.csv\",index=False)\n",
        "print(\"Training data saved\")\n",
        "testing=pd.DataFrame(test_pca)\n",
        "testing['label']=pd.Series(y_test).reset_index(drop=True)\n",
        "testing.to_csv(\"Testing_PCA_oversampled.csv\",index=False)\n",
        "print(\"Testing data saved\")\n",
        "#histogram representation of SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_label_distribution(y, title):\n",
        "    # Count label occurrences\n",
        "    count = pd.Series(y).value_counts()\n",
        "\n",
        "    # Ensure all classes (0 to 4) are present\n",
        "    classes = [0, 1, 2, 3, 4]\n",
        "    count = count.reindex(classes, fill_value=0)\n",
        "\n",
        "    # Plot bar chart\n",
        "    plt.bar(count.index, count.values, color='lightblue', edgecolor='black')\n",
        "\n",
        "    # Add text labels on top of bars\n",
        "    for i, v in enumerate(count.values):\n",
        "        plt.text(i, v + 5, str(v), ha='center')\n",
        "\n",
        "    # Formatting\n",
        "    plt.xlabel(\"Class Labels\")\n",
        "    plt.ylabel(\"Samples\")\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.title(title)\n",
        "\n",
        "# Create subplots for Training and Test labels\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_label_distribution(y_train_oversampled, \"Training Labels Distribution\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7iap5QfFqAUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASS WEIGHT"
      ],
      "metadata": {
        "id": "7FO58sNvqN87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"Training_PCA.csv\")\n",
        "test_data = pd.read_csv(\"Testing_PCA.csv\")\n",
        "\n",
        "# Split features and labels\n",
        "X_train = train_data.iloc[:, :-1]  # All columns except the last one\n",
        "y_train = train_data.iloc[:, -1]   # Last column as target\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "print(f\"Train:{X_train.shape}\")\n",
        "print(f\"Train:{X_test.shape}\")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights\n",
        "classes = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "# Compute sample weights for each class\n",
        "sample_weights = np.array([class_weights[class_] for class_ in y_train])\n",
        "print(sample_weights)"
      ],
      "metadata": {
        "id": "wNtvrAStqNn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XG+OPTUNA"
      ],
      "metadata": {
        "id": "R2xoy5wEqmcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        \"objective\": \"multi:softmax\",\n",
        "        \"num_class\": len(np.unique(y_train)),\n",
        "        \"eval_metric\": \"mlogloss\",\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0, log=True),\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    macro_f1s = []\n",
        "    weighted_f1s = []\n",
        "\n",
        "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "        sw_tr = sample_weights[train_idx]\n",
        "\n",
        "        model = xgb.XGBClassifier(**param)\n",
        "        model.fit(X_tr, y_tr, sample_weight=sw_tr)\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        macro_f1s.append(f1_score(y_val, preds, average=\"macro\"))\n",
        "        weighted_f1s.append(f1_score(y_val, preds, average=\"weighted\"))\n",
        "\n",
        "    avg_macro_f1 = np.mean(macro_f1s)\n",
        "    avg_weighted_f1 = np.mean(weighted_f1s)\n",
        "\n",
        "    trial.set_user_attr(\"macro_f1\", avg_macro_f1)\n",
        "    return avg_weighted_f1\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "# Print best results\n",
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best Weighted F1 Score:\", study.best_value)\n",
        "print(\"Corresponding Macro F1 Score:\", study.best_trial.user_attrs[\"macro_f1\"])\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from xgboost import XGBClassifier\n",
        "best_params = {'n_estimators': 300,\n",
        "               'max_depth': 6,\n",
        "               'learning_rate': 0.2567451389613149,\n",
        "              'subsample': 0.8400092987532728,\n",
        "              'colsample_bytree': 0.8464805154502861,\n",
        "              'gamma': 0.046440916333720494,\n",
        "              'reg_lambda': 1.6414868645406089,\n",
        "              'reg_alpha': 0.49211449804115437}\n",
        "model = XGBClassifier(**best_params)\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "print(\"📊 Classification Report - Train (SMOTE applied):\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "print(\"\\n📊 Classification Report - Test:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "train_macro_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "test_macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"\\n Train Macro F1 Score: {train_macro_f1:.4f}\")\n",
        "print(f\" Test Macro F1 Score: {test_macro_f1:.4f}\")"
      ],
      "metadata": {
        "id": "3bn6ceiwpzOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM FOREST"
      ],
      "metadata": {
        "id": "tBygTfLJqypn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score,classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        max_depth=trial.suggest_int(\"max_depth\", 10, 40),\n",
        "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
        "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
        "        class_weight=class_weights,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "\n",
        "    return f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Create and run the Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "# Train final model using best parameters\n",
        "best_params = study.best_params\n",
        "print(\" Best Parameters:\", best_params)\n",
        "\n",
        "# Recompute sample weights for full train set (in case of retraining on full data later)\n",
        "sample_weights = np.array([class_weights[class_] for class_ in y_train])\n",
        "\n",
        "# Re-train with best params\n",
        "best_rf = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
        "best_rf.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "y_test_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Weighted F1-score:\", f1_score(y_test, y_test_pred, average='weighted'))\n",
        "print(\"Macro F1-score:\", f1_score(y_test, y_test_pred, average='macro'))\n",
        "print(\"Micro F1-score:\", f1_score(y_test, y_test_pred, average='micro'))\n",
        "\n",
        "print(\"\\n Classification Report - Test:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "JLlYckaqq1A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinearSVC"
      ],
      "metadata": {
        "id": "Lyfn1MZDrwuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest the regularization parameter C and class weights\n",
        "    C = trial.suggest_float(\"linearsvc__C\", 0.01, 10.0, log=True)\n",
        "\n",
        "    # Build the pipeline with class weights\n",
        "    pipeline = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        LinearSVC(C=C, max_iter=10000, dual=False, class_weight=class_weights)\n",
        "    )\n",
        "\n",
        "    # Evaluate using cross-validation (macro F1)\n",
        "    macro_f1 = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=\"f1_macro\", n_jobs=-1).mean()\n",
        "    return macro_f1\n",
        "\n",
        "# Run the optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=30, timeout=300)\n",
        "\n",
        "# Train with best parameters\n",
        "best_C = study.best_params[\"linearsvc__C\"]\n",
        "\n",
        "best_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LinearSVC(C=best_C, max_iter=10000, dual=False, class_weight=class_weights)\n",
        ")\n",
        "\n",
        "best_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predictions & Evaluation\n",
        "linear_preds = best_pipeline.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Best Params for LinearSVC:\", study.best_params)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, linear_preds, target_names=np.unique(y_test).astype(str)))"
      ],
      "metadata": {
        "id": "wvgrBpZqu_He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "svc"
      ],
      "metadata": {
        "id": "JHyKIw1Evz-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Manually set the best parameters\n",
        "best_params = {'C': 0.6811111135767808, 'kernel': 'rbf', 'gamma': 'scale'}\n",
        "print(\"Best Params for SVC:\", best_params)\n",
        "\n",
        "# Train final SVC with best parameters\n",
        "best_svc = SVC(**best_params, random_state=42)\n",
        "best_svc.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "train_preds = best_svc.predict(X_train)\n",
        "test_preds = best_svc.predict(X_test)\n",
        "\n",
        "# Macro F1 scores\n",
        "train_f1 = f1_score(y_train, train_preds, average='macro')\n",
        "test_f1 = f1_score(y_test, test_preds, average='macro')\n",
        "\n",
        "print(f\"\\n Macro F1-score on Training Data: {train_f1:.4f}\")\n",
        "print(f\" Macro F1-score on Test Data: {test_f1:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n📋 Classification Report on Test Data:\\n\")\n",
        "print(classification_report(y_test, test_preds))"
      ],
      "metadata": {
        "id": "2PxvBWMQvzpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "levyja"
      ],
      "metadata": {
        "id": "TkBP0H2NwxsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as npa\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from xgboost import XGBClassifier\n",
        "import random\n",
        "import scipy.stats as stats\n",
        "\n",
        "train_data = pd.read_csv(\"Training_PCA.csv\")\n",
        "test_data = pd.read_csv(\"Testing_PCA.csv\")\n",
        "\n",
        "X_train = train_data.iloc[:, :-1]\n",
        "y_train = train_data.iloc[:, -1]\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "\n",
        "# Compute sample weights\n",
        "classes = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "sample_weights = np.array([class_weights[label] for label in y_train])\n",
        "\n",
        "# ----------------------- Optuna Best Params (Initial Point) -----------------------\n",
        "best_params = {\n",
        "    'n_estimators': 300,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.2567451389613149,\n",
        "    'subsample': 0.8400092987532728,\n",
        "    'colsample_bytree': 0.8464805154502861,\n",
        "    'gamma': 0.046440916333720494,\n",
        "    'reg_lambda': 1.6414868645406089,\n",
        "    'reg_alpha': 0.49211449804115437\n",
        "}\n",
        "\n",
        "# ----------------------- Define Bounds Based on Best Params -----------------------\n",
        "param_bounds = {\n",
        "    'learning_rate': (best_params['learning_rate'] * 0.5, best_params['learning_rate'] * 1.5),\n",
        "    'max_depth': (max(3, best_params['max_depth'] - 2), min(15, best_params['max_depth'] + 2)),\n",
        "    'subsample': (best_params['subsample'] * 0.8, 1.0),\n",
        "    'colsample_bytree': (best_params['colsample_bytree'] * 0.8, 1.0),\n",
        "    'gamma': (0.0, best_params['gamma'] * 1.5),\n",
        "    'reg_lambda': (max(1e-3, best_params['reg_lambda'] * 0.5), best_params['reg_lambda'] * 1.5),\n",
        "    'reg_alpha': (max(1e-3, best_params['reg_alpha'] * 0.5), best_params['reg_alpha'] * 1.5),\n",
        "    'n_estimators': (int(best_params['n_estimators'] * 0.8), best_params['n_estimators'])\n",
        "}\n",
        "\n",
        "# ----------------------- Levy Flight Generator -----------------------\n",
        "def levy_flight(beta=1.5, size=1):\n",
        "    sigma_u = (stats.gamma(1 + beta).pdf(1) * np.sin(np.pi * beta / 2) /\n",
        "               (stats.gamma((1 + beta) / 2).pdf(1) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n",
        "    u = np.random.normal(0, sigma_u, size=size)\n",
        "    v = np.random.normal(0, 1, size=size)\n",
        "    step = u / (np.abs(v) ** (1 / beta))\n",
        "    return step\n",
        "\n",
        "# ----------------------- Fitness Function (macro F1) -----------------------\n",
        "def fitness_function(params):\n",
        "    model = XGBClassifier(**params,\n",
        "                          objective='multi:softmax',\n",
        "                          num_class=len(np.unique(y_train)),\n",
        "                          eval_metric='mlogloss',\n",
        "                          use_label_encoder=False,\n",
        "                          verbosity=0)\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "    y_pred = model.predict(X_test)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    return macro_f1\n",
        "\n",
        "# ----------------------- Lévy JA Optimizer -----------------------\n",
        "def levy_ja(fitness_func, param_bounds, num_agents=10, max_iter=20):\n",
        "    agents = []\n",
        "    for _ in range(num_agents):\n",
        "        agent = {k: np.random.uniform(low, high) for k, (low, high) in param_bounds.items()}\n",
        "        agent['max_depth'] = int(agent['max_depth'])\n",
        "        agent['n_estimators'] = int(agent['n_estimators'])\n",
        "        agents.append(agent)\n",
        "\n",
        "    best_agent = max(agents, key=fitness_func)\n",
        "    best_score = fitness_func(best_agent)\n",
        "\n",
        "    for iteration in range(1, max_iter + 1):\n",
        "        for i in range(num_agents):\n",
        "            new_agent = {}\n",
        "            for key in param_bounds.keys():\n",
        "                step = levy_flight(beta=1.5, size=1)[0]\n",
        "                val = agents[i][key] + step * (agents[i][key] - best_agent[key])\n",
        "                low, high = param_bounds[key]\n",
        "                if isinstance(low, int) or 'int' in key or key in ['max_depth', 'n_estimators']:\n",
        "                    val = int(np.clip(val, low, high))\n",
        "                else:\n",
        "                    val = float(np.clip(val, low, high))\n",
        "                new_agent[key] = val\n",
        "\n",
        "            new_agent['max_depth'] = int(new_agent['max_depth'])\n",
        "            new_agent['n_estimators'] = int(new_agent['n_estimators'])\n",
        "\n",
        "            new_score = fitness_func(new_agent)\n",
        "            if new_score > fitness_func(agents[i]):\n",
        "                agents[i] = new_agent\n",
        "                if new_score > best_score:\n",
        "                    best_score = new_score\n",
        "                    best_agent = new_agent\n",
        "\n",
        "        print(f\"Iteration {iteration} | Best Macro F1 Score: {best_score:.4f}\")\n",
        "\n",
        "    return best_agent, best_score\n",
        "\n",
        "# ----------------------- Run Lévy JA Optimization -----------------------\n",
        "print(\"Running Lévy JA optimization (objective: macro F1)...\")\n",
        "best_levy_params, best_macro_f1 = levy_ja(fitness_function, param_bounds, num_agents=10, max_iter=20)\n",
        "\n",
        "# ----------------------- Train Final Model -----------------------\n",
        "print(\"\\nTraining final model with optimized parameters...\")\n",
        "model = XGBClassifier(**best_levy_params,\n",
        "                      objective='multi:softmax',\n",
        "                      num_class=len(np.unique(y_train)),\n",
        "                      eval_metric='mlogloss',\n",
        "                      use_label_encoder=False,\n",
        "                      verbosity=0)\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# ----------------------- Predictions -----------------------\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# ----------------------- Evaluation -----------------------\n",
        "print(\"\\n Classification Report - Train:\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "print(\"\\nClassification Report - Test:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "train_macro_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "test_macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print(f\"\\n Train Macro F1 Score: {train_macro_f1:.4f}\")\n",
        "print(f\" Test Macro F1 Score: {test_macro_f1:.4f}\")\n",
        "\n",
        "print(\"\\n Best Parameters Found by Lévy JA:\")\n",
        "print(best_levy_params)\n",
        "print(f\"Best Macro F1 Score: {best_macro_f1:.4f}\")"
      ],
      "metadata": {
        "id": "SERFieGqwzQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "enhanced AEO"
      ],
      "metadata": {
        "id": "xv2OaKLPxuGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mealpy==3.0.1\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"Training_PCA.csv\")\n",
        "test_data = pd.read_csv(\"Testing_PCA.csv\")\n",
        "\n",
        "# Split features and labels\n",
        "X_train = train_data.iloc[:, :-1]  # All columns except the last one\n",
        "y_train = train_data.iloc[:, -1]   # Last column as target\n",
        "X_test = test_data.iloc[:, :-1]\n",
        "y_test = test_data.iloc[:, -1]\n",
        "print(f\"Train:{X_train.shape}\")\n",
        "print(f\"Train:{X_test.shape}\")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights\n",
        "classes = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "# Compute sample weights for each class\n",
        "sample_weights = np.array([class_weights[class_] for class_ in y_train])\n",
        "print(sample_weights)\n",
        "\n",
        "\n",
        "#enhanced AEO\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from xgboost import XGBClassifier\n",
        "from mealpy import FloatVar, IntegerVar\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from mealpy.system_based.AEO import EnhancedAEO\n",
        "def objective_func(solution):\n",
        "    n_estimators = int(solution[0])\n",
        "    max_depth = int(solution[1])\n",
        "    learning_rate = solution[2]\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        learning_rate=learning_rate,\n",
        "    )\n",
        "\n",
        "    # Fit the model directly on the training data with sample weights\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the F1 score on the validation set (macro average)\n",
        "    score = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    return -score\n",
        "problem_dict = {\n",
        "    \"obj_func\": objective_func,\n",
        "    \"bounds\": [\n",
        "        IntegerVar(lb=250, ub=350),    # n_estimators\n",
        "        IntegerVar(lb=4, ub=8),      # max_depth\n",
        "        FloatVar(lb=0.2067, ub=0.3067),    # learning_rate\n",
        "    ],\n",
        "    \"minmax\": \"min\",\n",
        "}\n",
        "model = EnhancedAEO(epoch=20, pop_size=10)\n",
        "model.solve(problem_dict)\n",
        "\n",
        "best_params = model.g_best.solution\n",
        "best_macro_f1 = -model.g_best.target.fitness  # flip sign\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Macro F1 Score:\", best_macro_f1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# F1 scores from your logs (converted from negative to positive)\n",
        "f1_scores = [\n",
        "    0.9512974517681467,\n",
        "    0.9512974517681467,\n",
        "    0.9514630839626074,\n",
        "    0.9514912950542224,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "    0.9517214667287547,\n",
        "]\n",
        "\n",
        "epochs = list(range(1, len(f1_scores) + 1))\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, f1_scores, marker='o', color='green')\n",
        "plt.title('Macro F1 Score over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Macro F1 Score')\n",
        "plt.ylim(0.951, 0.9520)\n",
        "plt.grid(True)\n",
        "plt.xticks(epochs)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"EnhancedAEO.png\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GVbZkTe2xukS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "jade"
      ],
      "metadata": {
        "id": "VoOBt0mwx2np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#XGboost+JADE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from xgboost import XGBClassifier\n",
        "from mealpy import FloatVar, IntegerVar\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from mealpy.evolutionary_based.DE import JADE\n",
        "\n",
        "\n",
        "def objective_func(solution):\n",
        "    n_estimators = int(solution[0])\n",
        "    max_depth = int(solution[1])\n",
        "    learning_rate = solution[2]\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        learning_rate=learning_rate,\n",
        "    )\n",
        "\n",
        "    # Fit the model directly on the training data with sample weights\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the F1 score on the validation set (macro average)\n",
        "    score = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    return score\n",
        "\n",
        "problem_dict = {\n",
        "    \"obj_func\": objective_func,\n",
        "    \"bounds\": [\n",
        "        IntegerVar(lb=250, ub=350),    # n_estimators\n",
        "        IntegerVar(lb=4, ub=8),      # max_depth\n",
        "        FloatVar(lb=0.2067, ub=0.3067),    # learning_rate\n",
        "    ],\n",
        "    \"minmax\": \"max\",\n",
        "}\n",
        "model = JADE(epoch=20, pop_size=10)\n",
        "model.solve(problem_dict)\n",
        "\n",
        "best_params = model.g_best.solution\n",
        "best_macro_f1 = model.g_best.target.fitness  # flip sign\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Macro F1 Score:\", best_macro_f1)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extracted F1 scores from the JADE log\n",
        "f1_scores = [\n",
        "    0.9493475848498999,\n",
        "    0.9493475848498999,\n",
        "    0.9516667449690784,\n",
        "    0.9516667449690784,\n",
        "    0.9516667449690784,\n",
        "    0.9516667449690784,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.9516811576171575,\n",
        "    0.952600968671377,\n",
        "]\n",
        "\n",
        "epochs = list(range(1, len(f1_scores) + 1))\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, f1_scores, marker='o', color='blue')\n",
        "plt.title('JADE: Macro F1 Score over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Macro F1 Score')\n",
        "plt.ylim(min(f1_scores) - 0.0005, max(f1_scores) + 0.0005)\n",
        "plt.grid(True)\n",
        "plt.xticks(epochs)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"JADE.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FOECd720x3MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OrgJA"
      ],
      "metadata": {
        "id": "9ix8tzAxyfn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#orgJA\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        \"objective\": \"multi:softmax\",\n",
        "        \"num_class\": len(np.unique(y_train)),\n",
        "        \"eval_metric\": \"mlogloss\",\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0, log=True),\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    macro_f1s = []\n",
        "    weighted_f1s = []\n",
        "\n",
        "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "        sw_tr = sample_weights[train_idx]\n",
        "\n",
        "        model = xgb.XGBClassifier(**param)\n",
        "        model.fit(X_tr, y_tr, sample_weight=sw_tr)\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        macro_f1s.append(f1_score(y_val, preds, average=\"macro\"))\n",
        "        weighted_f1s.append(f1_score(y_val, preds, average=\"weighted\"))\n",
        "\n",
        "    avg_macro_f1 = np.mean(macro_f1s)\n",
        "    avg_weighted_f1 = np.mean(weighted_f1s)\n",
        "\n",
        "    trial.set_user_attr(\"macro_f1\", avg_macro_f1)\n",
        "    return avg_weighted_f1\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "# Print best results\n",
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best Weighted F1 Score:\", study.best_value)\n",
        "print(\"Corresponding Macro F1 Score:\", study.best_trial.user_attrs[\"macro_f1\"])\n",
        "\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define param_bounds (param_ranges)\n",
        "param_bounds = {\n",
        "    'max_depth': (4, 8),          # ±2 around 6\n",
        "    'learning_rate': (0.2067, 0.3067),  # ±0.05 around 0.2567\n",
        "    'n_estimators': (250, 350),  # ±50 around 300\n",
        "    'gamma': (0.0, 0.096),       # ±0.05 around 0.046\n",
        "    'subsample': (0.74, 0.94),    # ±0.1 around 0.84\n",
        "    'colsample_bytree': (0.746, 0.946),  # ±0.1 around 0.846\n",
        "}\n",
        "\n",
        "# Fitness function for XGBoost model\n",
        "def fitness_func(params):\n",
        "    max_depth, learning_rate, n_estimators, gamma, subsample, colsample_bytree = params\n",
        "    model = XGBClassifier(\n",
        "        max_depth=int(max_depth),\n",
        "        learning_rate=learning_rate,\n",
        "        n_estimators=int(n_estimators),\n",
        "        gamma=gamma,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        objective='multi:softmax',\n",
        "        num_class=len(np.unique(y_train)),\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "    preds = model.predict(X_test)\n",
        "    macro_f1 = f1_score(y_test, preds, average='macro')\n",
        "    return 1 - macro_f1  # Minimize 1 - macro F1 score (maximize F1)\n",
        "\n",
        "# Initialize population randomly within bounds\n",
        "def initialize_population():\n",
        "    population = []\n",
        "    for _ in range(population_size):\n",
        "        individual = []\n",
        "        for key in param_bounds:\n",
        "            low, high = param_bounds[key]\n",
        "            value = np.random.uniform(low, high)\n",
        "            individual.append(value)\n",
        "        population.append(individual)\n",
        "    return np.array(population)\n",
        "\n",
        "# Jaya update function for OriginalJA\n",
        "def jaya_update(population, best_solution, worst_solution):\n",
        "    new_population = []\n",
        "    for x in population:\n",
        "        r1, r2 = np.random.rand(), np.random.rand()\n",
        "        new_x = x + r1 * (best_solution - np.abs(x)) - r2 * (worst_solution - np.abs(x))\n",
        "\n",
        "        # Clip to bounds\n",
        "        for i, key in enumerate(param_bounds):\n",
        "            low, high = param_bounds[key]\n",
        "            new_x[i] = np.clip(new_x[i], low, high)\n",
        "        new_population.append(new_x)\n",
        "    return np.array(new_population)\n",
        "\n",
        "# Original Jaya Algorithm loop\n",
        "def original_jaya_algorithm():\n",
        "    population = initialize_population()\n",
        "    fitness = np.array([fitness_func(ind) for ind in population])\n",
        "\n",
        "    best_idx = np.argmin(fitness)\n",
        "    best_solution = population[best_idx]\n",
        "    best_score = fitness[best_idx]\n",
        "\n",
        "    worst_idx = np.argmax(fitness)\n",
        "    worst_solution = population[worst_idx]\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        population = jaya_update(population, best_solution, worst_solution)\n",
        "        fitness = np.array([fitness_func(ind) for ind in population])\n",
        "\n",
        "        current_best_idx = np.argmin(fitness)\n",
        "        current_worst_idx = np.argmax(fitness)\n",
        "\n",
        "        if fitness[current_best_idx] < best_score:\n",
        "            best_solution = population[current_best_idx]\n",
        "            best_score = fitness[current_best_idx]\n",
        "        if fitness[current_worst_idx] > best_score:\n",
        "            worst_solution = population[current_worst_idx]\n",
        "\n",
        "        # Print the progress for each iteration\n",
        "        print(f\"Iteration {t+1} | Best Macro F1 Score: {1 - best_score:.4f}\")\n",
        "\n",
        "    return best_solution, 1 - best_score\n",
        "\n",
        "# Set the population size and maximum iterations for OriginalJA\n",
        "population_size = 10\n",
        "max_iter = 20\n",
        "\n",
        "# Run OriginalJA optimization\n",
        "best_params_ja, best_f1_ja = original_jaya_algorithm()\n",
        "\n",
        "# Show Final Best Parameters\n",
        "param_names = list(param_bounds.keys())\n",
        "final_params = {k: (int(v) if 'int' in str(type(param_bounds[k][0])) else round(v, 4))\n",
        "                for k, v in zip(param_names, best_params_ja)}\n",
        "\n",
        "print(\"\\n✅ Best Parameters Found by OriginalJA:\")\n",
        "print(final_params)\n",
        "print(f\"Best Macro F1 Score: {best_f1_ja:.4f}\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data - replace with your actual F1 scores from Original JA\n",
        "iterations = list(range(1, 21))  # 20 iterations\n",
        "macro_f1_scores = [0.9498,\n",
        "0.9498,0.9516,0.9516,0.9524,0.9524,0.9524,0.9524,0.9524,\n",
        "0.9524,0.9524,0.9524,0.9524,0.9524,0.9524,0.9524,0.9524,0.9524,0.9524,0.9524]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iterations, macro_f1_scores, marker='o', color='blue', label='Original JA')\n",
        "\n",
        "# Styling\n",
        "plt.title('Original JA Optimization - Macro F1 Score per Iteration')\n",
        "plt.xlabel('Iteration Number')\n",
        "plt.ylabel('Macro F1 Score')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"OrginalJA.png\",dpi=300)\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VdaE6JVCykAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}